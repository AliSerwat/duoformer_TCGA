{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8d38dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65da1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_containing_this_file = Path(__file__).resolve().parent\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585bd7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, dir_containing_this_file)\n",
    "import torch\n",
    "import timm\n",
    "from timm.models.vision_transformer import VisionTransformer\n",
    "from timm.layers import Mlp, DropPath\n",
    "from timm.models.resnetv2 import ResNetV2\n",
    "from torch import nn\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa264cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchvision.models import ResNet50_Weights,ResNet18_Weights\n",
    "# from .multi_vision_transformer import *\n",
    "# from .multiscale_attn import *\n",
    "# from .projection_head import *\n",
    "# from .scale_attention import *\n",
    "# from .backbone import *\n",
    "from multi_vision_transformer import *\n",
    "from multiscale_attn import *\n",
    "from projection_head import *\n",
    "from scale_attention import *\n",
    "from backbone import *\n",
    "from resnet50ssl import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372b31ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel_no_extra_params(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        depth=None,\n",
    "        embed_dim=768,\n",
    "        num_heads=12,\n",
    "        init_values=1e-5,\n",
    "        num_classes=2,\n",
    "        num_layers=4,\n",
    "        num_patches=49,\n",
    "        mlp_ratio=4.0,\n",
    "        attn_drop_rate=0.0,\n",
    "        proj_drop_rate=0.0,\n",
    "        proj_dim=768,\n",
    "        freeze_backbone=True,\n",
    "        backbone=\"r50\",\n",
    "        scale_token=\"random\",\n",
    "        patch_attn=True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.proj_dim = proj_dim\n",
    "        self.backbone = backbone\n",
    "        self.scale_token = scale_token\n",
    "        self.patch_attn = patch_attn\n",
    "        if backbone == \"r50\":\n",
    "            # self.resnet_projector = nn.Sequential(*list(models.resnet50(weights=ResNet50_Weights.DEFAULT).children())[:-2])\n",
    "            self.resnet_projector = nn.Sequential(\n",
    "                *list(models.resnet50(pretrained=True).children())[:-2]\n",
    "            )\n",
    "            print(\"Resnet 50 pretrained weights loaded!\")\n",
    "        elif backbone == \"r18\":\n",
    "            # self.resnet_projector = nn.Sequential(*list(models.resnet18(weights=ResNet18_Weights.DEFAULT).children())[:-2])\n",
    "            self.resnet_projector = nn.Sequential(\n",
    "                *list(models.resnet18(pretrained=True).children())[:-2]\n",
    "            )\n",
    "            print(\"Resnet 18 pretrained weights loaded!\")\n",
    "        elif backbone == \"r50_Swav\":\n",
    "            self.resnet_projector = resnet50FeatureExtractor(\n",
    "                pretrained=True, progress=False, key=\"SwAV\"\n",
    "            )  # MoCoV2, BT ,removed the fc\n",
    "            print(\"Weights of Resnet 50 pretrained on TCGA+TULIP loaded!\")\n",
    "\n",
    "        if freeze_backbone:  # freeze the backbone in training or not\n",
    "            for param in self.resnet_projector.parameters():\n",
    "                param.requires_grad = False\n",
    "            print(\"Backbone freezed during training!\")\n",
    "\n",
    "        if self.scale_token == \"random\":\n",
    "            self.channel_token = torch.nn.Parameter(torch.randn(1, 1, 1, self.proj_dim))\n",
    "            nn.init.normal_(self.channel_token, std=0.036)  # 0.036,1e-6\n",
    "        elif self.scale_token == \"channel\":  # 0.036,1e-6\n",
    "            self.chann_proj1 = Channel_Projector_layer1(backbone=backbone)\n",
    "            self.chann_proj2 = Channel_Projector_layer2(backbone=backbone)\n",
    "            self.chann_proj3 = Channel_Projector_layer3()\n",
    "            self.chann_proj_all = Channel_Projector_All(backbone=backbone)\n",
    "\n",
    "        self.projection = Projection(\n",
    "            num_layers=self.num_layers, proj_dim=self.proj_dim, backbone=backbone\n",
    "        )\n",
    "        self.vision_transformer = MultiscaleFormer(\n",
    "            depth=depth,\n",
    "            scales=self.num_layers,\n",
    "            num_heads=num_heads,\n",
    "            embed_dim=embed_dim,\n",
    "            mlp_ratio=mlp_ratio,\n",
    "            qkv_bias=True,\n",
    "            qk_norm=False,\n",
    "            proj_drop_rate=proj_drop_rate,\n",
    "            attn_drop_rate=attn_drop_rate,\n",
    "            norm_layer=None,\n",
    "            act_layer=None,\n",
    "            init_values=None,\n",
    "            num_classes=num_classes,\n",
    "            num_patches=num_patches,\n",
    "            scale_token=scale_token,\n",
    "            patch_attn=patch_attn,\n",
    "        )\n",
    "        print(\"Multiscaletransformer implemented from scratch!\")\n",
    "\n",
    "        # self.scale_former = ScaleFormer(depth=12,scales=self.num_layers,num_heads=12,embed_dim=self.proj_dim)   # only scale attentions, consistent with pretrained hybrid\n",
    "        self.index = {}\n",
    "        for i in range(4):\n",
    "            self.index[f\"{4-i-1}\"] = torch.empty([49, 4**i], dtype=torch.int64)\n",
    "        for r in range(7):\n",
    "            for c in range(7):\n",
    "                p = r * 7 + c\n",
    "                self.index[\"3\"][p, :] = p\n",
    "                self.index[\"2\"][p, :] = torch.IntTensor(\n",
    "                    [\n",
    "                        2 * r * 14 + 2 * c,\n",
    "                        (2 * r + 1) * 14 + 2 * c,\n",
    "                        2 * r * 14 + (2 * c + 1),\n",
    "                        (2 * r + 1) * 14 + (2 * c + 1),\n",
    "                    ]\n",
    "                )\n",
    "                self.index[\"1\"][p, :] = torch.IntTensor(\n",
    "                    [\n",
    "                        4 * r * 28 + 4 * c,\n",
    "                        4 * r * 28 + 4 * c + 1,\n",
    "                        4 * r * 28 + 4 * c + 2,\n",
    "                        4 * r * 28 + 4 * c + 3,\n",
    "                        (4 * r + 1) * 28 + 4 * c,\n",
    "                        (4 * r + 1) * 28 + 4 * c + 1,\n",
    "                        (4 * r + 1) * 28 + 4 * c + 2,\n",
    "                        (4 * r + 1) * 28 + 4 * c + 3,\n",
    "                        (4 * r + 2) * 28 + 4 * c,\n",
    "                        (4 * r + 2) * 28 + 4 * c + 1,\n",
    "                        (4 * r + 2) * 28 + 4 * c + 2,\n",
    "                        (4 * r + 2) * 28 + 4 * c + 3,\n",
    "                        (4 * r + 3) * 28 + 4 * c,\n",
    "                        (4 * r + 3) * 28 + 4 * c + 1,\n",
    "                        (4 * r + 3) * 28 + 4 * c + 2,\n",
    "                        (4 * r + 3) * 28 + 4 * c + 3,\n",
    "                    ]\n",
    "                )\n",
    "                self.index[\"0\"][p, :] = torch.IntTensor(\n",
    "                    [\n",
    "                        8 * r * 56 + 8 * c,\n",
    "                        8 * r * 56 + 8 * c + 1,\n",
    "                        8 * r * 56 + 8 * c + 2,\n",
    "                        8 * r * 56 + 8 * c + 3,\n",
    "                        8 * r * 56 + 8 * c + 4,\n",
    "                        8 * r * 56 + 8 * c + 5,\n",
    "                        8 * r * 56 + 8 * c + 6,\n",
    "                        8 * r * 56 + 8 * c + 7,\n",
    "                        (8 * r + 1) * 56 + 8 * c,\n",
    "                        (8 * r + 1) * 56 + 8 * c + 1,\n",
    "                        (8 * r + 1) * 56 + 8 * c + 2,\n",
    "                        (8 * r + 1) * 56 + 8 * c + 3,\n",
    "                        (8 * r + 1) * 56 + 8 * c + 4,\n",
    "                        (8 * r + 1) * 56 + 8 * c + 5,\n",
    "                        (8 * r + 1) * 56 + 8 * c + 6,\n",
    "                        (8 * r + 1) * 56 + 8 * c + 7,\n",
    "                        (8 * r + 2) * 56 + 8 * c,\n",
    "                        (8 * r + 2) * 56 + 8 * c + 1,\n",
    "                        (8 * r + 2) * 56 + 8 * c + 2,\n",
    "                        (8 * r + 2) * 56 + 8 * c + 3,\n",
    "                        (8 * r + 2) * 56 + 8 * c + 4,\n",
    "                        (8 * r + 2) * 56 + 8 * c + 5,\n",
    "                        (8 * r + 2) * 56 + 8 * c + 6,\n",
    "                        (8 * r + 2) * 56 + 8 * c + 7,\n",
    "                        (8 * r + 3) * 56 + 8 * c,\n",
    "                        (8 * r + 3) * 56 + 8 * c + 1,\n",
    "                        (8 * r + 3) * 56 + 8 * c + 2,\n",
    "                        (8 * r + 3) * 56 + 8 * c + 3,\n",
    "                        (8 * r + 3) * 56 + 8 * c + 4,\n",
    "                        (8 * r + 3) * 56 + 8 * c + 5,\n",
    "                        (8 * r + 3) * 56 + 8 * c + 6,\n",
    "                        (8 * r + 3) * 56 + 8 * c + 7,\n",
    "                        (8 * r + 4) * 56 + 8 * c,\n",
    "                        (8 * r + 4) * 56 + 8 * c + 1,\n",
    "                        (8 * r + 4) * 56 + 8 * c + 2,\n",
    "                        (8 * r + 4) * 56 + 8 * c + 3,\n",
    "                        (8 * r + 4) * 56 + 8 * c + 4,\n",
    "                        (8 * r + 4) * 56 + 8 * c + 5,\n",
    "                        (8 * r + 4) * 56 + 8 * c + 6,\n",
    "                        (8 * r + 4) * 56 + 8 * c + 7,\n",
    "                        (8 * r + 5) * 56 + 8 * c,\n",
    "                        (8 * r + 5) * 56 + 8 * c + 1,\n",
    "                        (8 * r + 5) * 56 + 8 * c + 2,\n",
    "                        (8 * r + 5) * 56 + 8 * c + 3,\n",
    "                        (8 * r + 5) * 56 + 8 * c + 4,\n",
    "                        (8 * r + 5) * 56 + 8 * c + 5,\n",
    "                        (8 * r + 5) * 56 + 8 * c + 6,\n",
    "                        (8 * r + 5) * 56 + 8 * c + 7,\n",
    "                        (8 * r + 6) * 56 + 8 * c,\n",
    "                        (8 * r + 6) * 56 + 8 * c + 1,\n",
    "                        (8 * r + 6) * 56 + 8 * c + 2,\n",
    "                        (8 * r + 6) * 56 + 8 * c + 3,\n",
    "                        (8 * r + 6) * 56 + 8 * c + 4,\n",
    "                        (8 * r + 6) * 56 + 8 * c + 5,\n",
    "                        (8 * r + 6) * 56 + 8 * c + 6,\n",
    "                        (8 * r + 6) * 56 + 8 * c + 7,\n",
    "                        (8 * r + 7) * 56 + 8 * c,\n",
    "                        (8 * r + 7) * 56 + 8 * c + 1,\n",
    "                        (8 * r + 7) * 56 + 8 * c + 2,\n",
    "                        (8 * r + 7) * 56 + 8 * c + 3,\n",
    "                        (8 * r + 7) * 56 + 8 * c + 4,\n",
    "                        (8 * r + 7) * 56 + 8 * c + 5,\n",
    "                        (8 * r + 7) * 56 + 8 * c + 6,\n",
    "                        (8 * r + 7) * 56 + 8 * c + 7,\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "    def get_features(self, x):\n",
    "        layers = []\n",
    "        for i in range(4):  # self.num_layers\n",
    "            layers.append(str(7 - i))\n",
    "        # layers = ['4','5'] # '5','4'\n",
    "        features = {}\n",
    "        for name, module in list(self.resnet_projector.named_children()):\n",
    "            x = module(x)\n",
    "            if name in layers:\n",
    "                features[str(int(name) - 4)] = x\n",
    "        return features\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.backbone == \"r50_Swav\":\n",
    "            # x = self.get_features(x)  # feature extraction\n",
    "            x = self.resnet_projector(\n",
    "                x\n",
    "            )  # feature extraction for resnet 50 pretrained on TCGA, output is a list contains all scales\n",
    "            x = {str(i): output for i, output in enumerate(x)}\n",
    "        else:\n",
    "            x = self.get_features(x)\n",
    "\n",
    "        if self.scale_token == \"channel\":\n",
    "            channel_fuse = {}\n",
    "            channel_fuse[\"0\"] = self.chann_proj1(x[\"0\"])\n",
    "            channel_fuse[\"1\"] = self.chann_proj2(x[\"1\"])\n",
    "            channel_fuse[\"2\"] = self.chann_proj3(x[\"2\"])\n",
    "            channel_fuse[\"3\"] = x[\"3\"]\n",
    "            channel_fuse_all = torch.cat(\n",
    "                [channel_fuse[key] for key in sorted(channel_fuse.keys())], dim=1\n",
    "            )  # gather channel-wise information\n",
    "            channel_token = (\n",
    "                self.chann_proj_all(channel_fuse_all).unsqueeze(-1).permute(0, 2, 3, 1)\n",
    "            )  # 49,1,768\n",
    "            B, _, _, _ = channel_token.shape\n",
    "        else:\n",
    "            B, _, _, _ = x[\"0\"].shape\n",
    "        C = self.proj_dim\n",
    "        if self.num_layers == 2:\n",
    "            x = self.projection({\"2\": x[\"2\"], \"3\": x[\"3\"]})\n",
    "            x[\"3\"] = x[\"3\"].reshape(B, C, -1)\n",
    "            x[\"2\"] = x[\"2\"].reshape(B, C, -1)\n",
    "            # print(self.index['3'])\n",
    "            # print(x['3'])\n",
    "            x[\"3\"] = x[\"3\"][\n",
    "                :, :, self.index[\"3\"]\n",
    "            ]  # [64, 768, 7, 7] -> [64, 49, 1, 7, 7]\n",
    "            x[\"2\"] = x[\"2\"][\n",
    "                :, :, self.index[\"2\"]\n",
    "            ]  # [64, 768, 14, 14] -> [64, 49, 4, 14, 14]\n",
    "            x = torch.cat((x[\"3\"], x[\"2\"]), dim=-1).permute(\n",
    "                0, 2, 3, 1\n",
    "            )  # [64, 768, 49, 5] -> [64, 49, 5, 768]\n",
    "        elif self.num_layers == 4:\n",
    "            x = self.projection({\"0\": x[\"0\"], \"1\": x[\"1\"], \"2\": x[\"2\"], \"3\": x[\"3\"]})\n",
    "            x[\"3\"] = x[\"3\"].reshape(B, C, -1)\n",
    "            x[\"2\"] = x[\"2\"].reshape(B, C, -1)\n",
    "            x[\"3\"] = x[\"3\"][\n",
    "                :, :, self.index[\"3\"]\n",
    "            ]  # [64, 768, 7, 7] -> [64, 49, 1, 7, 7]\n",
    "            x[\"2\"] = x[\"2\"][\n",
    "                :, :, self.index[\"2\"]\n",
    "            ]  # [64, 768, 14, 14] -> [64, 49, 4, 14, 14]\n",
    "            x[\"1\"] = x[\"1\"].reshape(B, C, -1)\n",
    "            x[\"0\"] = x[\"0\"].reshape(B, C, -1)\n",
    "            x[\"1\"] = x[\"1\"][:, :, self.index[\"1\"]]\n",
    "            x[\"0\"] = x[\"0\"][:, :, self.index[\"0\"]]\n",
    "            x = torch.cat((x[\"3\"], x[\"2\"], x[\"1\"], x[\"0\"]), dim=-1).permute(0, 2, 3, 1)\n",
    "        elif self.num_layers == 3:\n",
    "            x = self.projection({\"1\": x[\"1\"], \"2\": x[\"2\"], \"3\": x[\"3\"]})\n",
    "            x[\"3\"] = x[\"3\"].reshape(B, C, -1)\n",
    "            x[\"2\"] = x[\"2\"].reshape(B, C, -1)\n",
    "            x[\"3\"] = x[\"3\"][\n",
    "                :, :, self.index[\"3\"]\n",
    "            ]  # [64, 768, 7, 7] -> [64, 49, 1, 7, 7]\n",
    "            x[\"2\"] = x[\"2\"][\n",
    "                :, :, self.index[\"2\"]\n",
    "            ]  # [64, 768, 14, 14] -> [64, 49, 4, 14, 14]\n",
    "            x[\"1\"] = x[\"1\"].reshape(B, C, -1)\n",
    "            x[\"1\"] = x[\"1\"][:, :, self.index[\"1\"]]\n",
    "            x = torch.cat((x[\"3\"], x[\"2\"], x[\"1\"]), dim=-1).permute(0, 2, 3, 1)\n",
    "\n",
    "        if self.scale_token == \"channel\":\n",
    "            x = torch.cat((channel_token, x), dim=2)\n",
    "        elif self.scale_token == \"random\":\n",
    "            x = torch.cat((self.channel_token.expand(B, 49, -1, -1), x), dim=2)\n",
    "\n",
    "        output = self.vision_transformer(x)  # multiscale transformer\n",
    "        return output"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
